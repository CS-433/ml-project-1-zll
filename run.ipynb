{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794d7a2a-3833-4800-880c-5b10480d877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2848d9a4-860a-4538-a58d-f06f54decae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed):   \n",
    "    \"\"\"split the train dataset to train and validation dataset based on the split ratio.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices\n",
    "    num_row = len(x)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_train = indices[: index_split]\n",
    "    index_val = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_train]\n",
    "    x_val = x[index_val]\n",
    "    y_tr = y[index_train]\n",
    "    y_val = y[index_val] \n",
    "    return x_tr, x_val, y_tr, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6cc685-3fc2-4a4d-8d24-a1f8f00ce415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy(Y_pred, Y_true):\n",
    "    # This function calculates prediction accuracy\n",
    "    acc = 1 - np.mean(np.abs(Y_pred - Y_true))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7145ab63-9407-42d9-b1dc-04546e251faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(num, k, seed):\n",
    "    \"\"\"build k indices for k-fold.  \n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "    \"\"\"\n",
    "    interval = int(num / k)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num)\n",
    "    k_indices = [indices[i * interval: (i + 1) * interval] for i in range(k)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7e4dc6-ec57-4548-be93-3443222b7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k):\n",
    "    \"\"\"Split the train dataset to train and validation dataset with respect to k-fold cross validation.\"\"\"\n",
    "    y_test = np.array([])\n",
    "    x_test = []\n",
    "    for i in k_indices[k]:\n",
    "        y_test = np.append(y_test, y[i])\n",
    "        x_test.append(x[i])\n",
    "    k_indices = np.delete(k_indices, k, axis=0)\n",
    "    k_indices = k_indices.ravel()\n",
    "    y_train = np.array([])\n",
    "    x_train = []\n",
    "    for i in k_indices:  \n",
    "        y_train = np.append(y_train, y[i])\n",
    "        x_train.append(x[i])\n",
    "    return np.array(x_train), np.array(x_test), y_train.reshape(-1, 1), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58c869f-254b-4d71-8134-e138a2b24c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv_data\n",
    "from helpers import create_csv_submission\n",
    "\n",
    "# load dataset\n",
    "y_train, tx_train, ids_train = load_csv_data(\"train.csv\")\n",
    "y_test, tx_test, ids_test = load_csv_data(\"test.csv\")\n",
    "\n",
    "# mapping labels from {-1, 1} to {0, 1} in order to apply logistic regression\n",
    "y_train[np.where(y_train == -1)] = 0\n",
    "\n",
    "# tx_train = np.c_[np.ones((tx_train.shape[0], 1)), tx_train]\n",
    "# tx_test = np.c_[np.ones((tx_test.shape[0], 1)), tx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43bdc192-0d96-4884-887d-54294a411afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract usable data                TBD\n",
    "# y_train, tx_train, ids_train\n",
    "# y_test, tx_test, ids_test\n",
    "# x_tr, x_val, y_tr, y_val\n",
    "\n",
    "# data preprocessing -- mean subtraction and normalization                TBD\n",
    "# y_train, tx_train, ids_train\n",
    "# y_test, tx_test, ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc8b15d-5bfe-44d9-909d-88f68b29ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train[0:1000].reshape(1000,1)\n",
    "# tx_train = tx_train[0:1000]\n",
    "# tx_test = tx_test[0:100]\n",
    "# ids_test = ids_test[0:100]\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "num = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86223823-8180-4bc8-ba74-8b02e62ac6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "k_fold = 5\n",
    "k_indices = build_k_indices(num, k_fold, seed)\n",
    "# x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k=3)\n",
    "# x_tr.shape, x_val.shape, y_tr.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe123c0-0434-4f76-83dc-298592172282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr, x_val, y_tr, y_val = split_data(tx_train, y_train, 0.75, 123)\n",
    "# y_tr = y_tr[0:5000].reshape(5000,1)\n",
    "# x_tr = x_tr[0:5000]\n",
    "# y_val = y_val[0:500].reshape(500,1)\n",
    "# x_val = x_val[0:500]\n",
    "# tx_test = tx_test[0:500]\n",
    "# ids_test = ids_test[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d43bb12-3cc5-40bd-8987-8511f3629247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "lambda_ = 0.001\n",
    "max_iters = 100\n",
    "gamma = 1E-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdba179-f6cb-42c8-8a85-0ffffe8fd023",
   "metadata": {},
   "source": [
    "Gradient Descent using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018e3dd-eb9d-4c81-a92a-92b0d89bbd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss with Gradient Descent(GD) using Logistic Regression:  0.6850475886633434\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = logistic_regression(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(_accuracy(y_pred, y_val)))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_logistic_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d1d75-90f5-40a6-97c6-d03cc1799aba",
   "metadata": {},
   "source": [
    "Gradient Descent using the regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2752f-c397-4679-bb9b-dd627f59a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss with Gradient Descent(GD) using Regularized Logistic Regression:  0.6850475886638354\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w, max_iters, gamma)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(_accuracy(y_pred, y_val)))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_reg_logistic_regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f85ca-be2b-49ac-a9b4-357a77a8adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient Descent (GD) algorithm using mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9204cb13-eb44-473c-8702-35289892c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss with Gradient Descent(GD):  0.15795799708846436\n",
      "test prediction acc of fold 0 is 0.635\n",
      "Average loss with Gradient Descent(GD):  0.16126874247942374\n",
      "test prediction acc of fold 1 is 0.6599999999999999\n",
      "Average loss with Gradient Descent(GD):  0.15550824691841403\n",
      "test prediction acc of fold 2 is 0.62\n",
      "Average loss with Gradient Descent(GD):  0.16385478688187705\n",
      "test prediction acc of fold 3 is 0.685\n",
      "Average loss with Gradient Descent(GD):  0.16095864919180175\n",
      "test prediction acc of fold 4 is 0.655\n",
      "Average test prediction accuracy over 5 folds is 0.651\n",
      "Average loss over 5 folds is 0.14974622349778105\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = mean_squared_error_gd(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(_accuracy(y_pred, y_val)))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_mean_squared_error_gd.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397dafd5-828b-4f4e-8597-479fa2bb2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stochastic Gradient Descent algorithm (SGD) using mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00081264-d34a-4663-8df2-6679a68eb9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss with Stochastic Gradient Descent(SGD):  0.17249324095030835\n",
      "test prediction acc of fold 0 is 0.635\n",
      "Average loss with Stochastic Gradient Descent(SGD):  0.1708745343707575\n",
      "test prediction acc of fold 1 is 0.6599999999999999\n",
      "Average loss with Stochastic Gradient Descent(SGD):  0.16063356367274031\n",
      "test prediction acc of fold 2 is 0.62\n",
      "Average loss with Stochastic Gradient Descent(SGD):  0.15484728776554804\n",
      "test prediction acc of fold 3 is 0.685\n",
      "Average loss with Stochastic Gradient Descent(SGD):  0.1683924914865847\n",
      "test prediction acc of fold 4 is 0.655\n",
      "Average test prediction accuracy over 5 folds is 0.651\n",
      "Average loss over 5 folds is 0.16025889510562785\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(_accuracy(y_pred, y_val)))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_mean_squared_error_sgd.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169ed93-e469-4d89-8167-4388c22ac774",
   "metadata": {},
   "outputs": [],
   "source": [
    "Least Squares solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e22ad-4458-4f04-913c-e2b467e97078",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dd/dynwp31j0jdb84y9vrd6bk_40000gn/T/ipykernel_5707/1746262903.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minitial_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k_fold' is not defined"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = least_squares(y_tr, x_tr)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(_accuracy(y_pred, y_val)))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_least_squares.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cf3ab-d4ac-4403-b843-edbcc198fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03c4eb71-bf9e-4220-8b6f-005417c0a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with Ridge Regression:  0.09262448403953812\n",
      "test prediction acc of fold 0 is 0.5783\n",
      "Loss with Ridge Regression:  0.0917095006290168\n",
      "test prediction acc of fold 1 is 0.5880000000000001\n",
      "Loss with Ridge Regression:  0.08798840439255518\n",
      "test prediction acc of fold 2 is 0.5816\n",
      "Loss with Ridge Regression:  0.09172792878266332\n",
      "test prediction acc of fold 3 is 0.611\n",
      "Loss with Ridge Regression:  0.08961510249957844\n",
      "test prediction acc of fold 4 is 0.59455\n",
      "Average test prediction accuracy over 5 folds is 0.59069\n",
      "Average loss over 5 folds is 0.09073308406867037\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for k in range(k_fold):\n",
    "    x_tr, x_val, y_tr, y_val = cross_validation(y_train, tx_train, k_indices, k)\n",
    "    initial_w = np.zeros((x_tr.shape[1],1))\n",
    "    w, loss = ridge_regression(y_tr, x_tr, lambda_)\n",
    "    y_pred = predict_labels(w, x_val)\n",
    "    acc = _accuracy(y_pred, y_val)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "    print(\"test prediction acc of fold \" + str(k) + \" is \" + str(acc))\n",
    "print(\"Average test prediction accuracy over \" + str(k_fold) + \" folds is \" + str(np.mean(accs)))\n",
    "print(\"Average loss over \" + str(k_fold) + \" folds is \" + str(np.mean(losses)))\n",
    "\n",
    "\n",
    "# create_csv_submission(ids_test, predictions, \"submission_ridge_regression.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dd781-adcc-491e-b040-08730abb7ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
